[{"categories":["projects"],"content":"Adapted from Data Science Enthusiast Nagesh's tutorial about writing NN in Python","date":"2022-01-18","objectID":"/ann_part1/","tags":["Python","ANN","Neural Network"],"title":"Write an ANN from Scratch Part I : Perceptron","uri":"/ann_part1/"},{"categories":["projects"],"content":"Please view my work here! Please checkout this Github Gist =\u003e To run the Colab just like I did, please click hereüôÇ. Special thanks to Nagesh‚Äôs tutorial which did an excellent job in explaining neural network in simple manners. Click to view part I of his tutorial series. ","date":"2022-01-18","objectID":"/ann_part1/:1:0","tags":["Python","ANN","Neural Network"],"title":"Write an ANN from Scratch Part I : Perceptron","uri":"/ann_part1/"},{"categories":["projects"],"content":"Explanation about Gradient Descent I quite like Nagesh‚Äôs explanation about gradient descent, which really illuminates the concept. I‚Äôm happy to reiterate it here as a refresher. Recall the formula: $$w = w - \\alpha (\\frac{\\partial F}{\\partial w})$$ $\\frac{\\partial F}{\\partial w}$ is the gradient of the loss F with respect to the weight w, which, to put simply, translates to rate change of the loss with the change of the weight and in 2-D term the slope. If the loss increases as weight increases, $\\frac{\\partial F}{\\partial w}$ would be a positive value which is then subtracted from w by the amount $\\alpha (\\frac{\\partial F}{\\partial w})$, to go in the opposite direction of the gradient. The same applies if the loss decreases as weight increases: it means $\\frac{\\partial F}{\\partial w}$ is a negative value which we in effect (minus a negative value) add the amount $\\alpha (\\frac{\\partial F}{\\partial w})$ to w. Either way, the goal is to push w in the direction that causes most rapid decline in F, the cost function we‚Äôre interested in minimizing. ","date":"2022-01-18","objectID":"/ann_part1/:2:0","tags":["Python","ANN","Neural Network"],"title":"Write an ANN from Scratch Part I : Perceptron","uri":"/ann_part1/"},{"categories":["projects"],"content":"Independent project via Python in Summer 2020 EconEx externship","date":"2020-08-09","objectID":"/covid19_analysis/","tags":["Python","data analysis"],"title":"NYC under Covid-19: An Analysis on Consumer and Retail Trends","uri":"/covid19_analysis/"},{"categories":["projects"],"content":"1. What I did In Summer 2020, I was fortunate to be selected into the EconEx externship program hosted by Econ department. Mentored by UW-Alumni and Data Scientist Micah Lanier, I completed an independent project analyzing New York City consumer and retail trends under Covid-19. Meanwhile, I self-learnt many useful data analysis techniques in Python, like how to use numpy, pandas, matplotlib ‚Ä¶ interpolation to fill in missing data and web scraping. ","date":"2020-08-09","objectID":"/covid19_analysis/:1:0","tags":["Python","data analysis"],"title":"NYC under Covid-19: An Analysis on Consumer and Retail Trends","uri":"/covid19_analysis/"},{"categories":["projects"],"content":"2. Final results For final deliverables, here is the whitepaper and I also made a video presentation: Here is the full code: (I attached it here but they‚Äôre also available on github repo) main.py: import pandas as pd import numpy as np from datetime import datetime import matplotlib.pyplot as plt %matplotlib inline df = pd.read_csv(\"us-counties.csv\",parse_dates=True,index_col=0) pd.options.display.max_rows = 10 df = df['20200304':'20200611'] df.reset_index(inplace=True) df t10 = df.groupby('state').sum().sort_values('cases', ascending=False).head(10) t10 = t10.drop(columns='fips') print (t10.index) t10_list = ['New York', 'New Jersey', 'Illinois', 'California', 'Massachusetts', 'Pennsylvania', 'Michigan', 'Texas', 'Florida', 'Louisiana'] t10 t_c = t10['cases'].to_list() t_d = t10['deaths'].to_list() x = np.arange(len(t10.index)) # the label locations width = 0.35 # the width of the bars fig, ax = plt.subplots(figsize=(12,5)) rects1 = ax.bar(x - width/2, t_c, width, label='cases') rects2 = ax.bar(x + width/2, t_d, width, label='deaths') # Add some text for labels, title and custom x-axis tick labels, etc. ax.set_ylabel('number') ax.set_title('Cases and deaths comparison across top 10 states') ax.set_xticks(x) ax.set_xticklabels(t10.index) #ax.set_yticks(y) #ax.set_yticklabels(y) ax.legend() fig.tight_layout() plt.show() # now I have obtained the top 10 states with cases confirmed. Next I want to plot the contrast between # cases and deaths over time for each state. cov19_counties_bystate_cases = pd.Series(df.groupby(['state','date']).cases.sum()) cov19_counties_bystate_deaths = pd.Series(df.groupby(['state','date']).deaths.sum()) cov19_counties_bystate = pd.DataFrame(cov19_counties_bystate_cases) cov19_counties_bystate['deaths'] = cov19_counties_bystate_deaths cov19_counties_bystate_deaths = pd.Series(cov19_counties.groupby(['state','date']).deaths.sum()) cov19_counties_bystate = pd.DataFrame(cov19_counties_bystate_cases) cov19_counties_bystate['deaths'] = cov19_counties_bystate_deaths cov19_counties_bystate from matplotlib.dates import DateFormatter import matplotlib.dates as mdates cov19_counties.date = pd.to_datetime(cov19_counties.date) pp.figure(figsize=(12,12)) for i, state in enumerate(t10.index): pp.subplot(5,2,i+1) #5 rows, 2 columns pp.plot(cov19_counties_bystate.loc[state].cases,label='cases') pp.plot(cov19_counties_bystate.loc[state].deaths,label='deaths') pp.legend() pp.title(state) #pp.xticks(arange(4), calendar.month_name[3:6+1], rotation=45) pp.tight_layout() # drop rows df = cov19_counties_bystate ax = cov19_counties_bystate.loc['New York'].cases.plot.line(figsize=(12,5)) ax = cov19_counties_bystate.loc['New Jersey'].cases.plot.line(figsize=(12,5)) ax = cov19_counties_bystate.loc['Illinois'].cases.plot.line(figsize=(12,5)) #ax = cov19_counties_bystate.loc['California'].cases.plot.line(figsize=(12,5))''' for state in t10.index[:4+1]: ax = cov19_counties_bystate.loc[state].cases.plot.line(figsize=(12,5)) ax.legend(t10.index[:4+1]) pp.title('states cases') for state in t10.index[:4+1]: ax = cov19_counties_bystate.loc[state].deaths.plot.line(figsize=(12,5)) ax.legend(t10.index[:4+1]) pp.title('states deaths') df[df.state == 'New York'] dfc = df[df.state == 'New York'].pivot_table(index = df[df.state == 'New York'].date, values='cases',aggfunc='sum') dfd = df[df.state == 'New York'].pivot_table(index = df[df.state == 'New York'].date, values='deaths',aggfunc='sum') ax = dfc.plot.line(figsize=(12,5),grid=True,rot=True) dfd.plot.line(figsize=(12,5),grid=True,rot=True,ax=ax) ax.set_xlabel(\"New York\") ax.set_ylabel(\"number\") def plotstate(state_name): dfc = df[df.state == state_name].pivot_table(index = df[df.state == state_name].date, values='cases',aggfunc='sum') dfd = df[df.state == state_name].pivot_table(index = df[df.state == state_name].date, values='deaths',aggfunc='sum') ax = dfc.plot.line(figsize=(12,5),grid=True,rot=True) dfd.plot.line(figsize=(12,5),grid=True,rot=True,ax=ax) ax.set_xlabel(state_name) ax.set_","date":"2020-08-09","objectID":"/covid19_analysis/:2:0","tags":["Python","data analysis"],"title":"NYC under Covid-19: An Analysis on Consumer and Retail Trends","uri":"/covid19_analysis/"},{"categories":["projects"],"content":"An overview of my work in Data Challenge hosted by UW-Madison Data Science Club","date":"2020-11-05","objectID":"/data_challenge_2020/","tags":["machine learning","statistics","data analysis","Python"],"title":"Heart Failure Death Prediction Project in Data Challenge 2020","uri":"/data_challenge_2020/"},{"categories":["projects"],"content":"1.What I did In Junior Fall 2020, I collaborated with Shaonan Wang, an ISYE major at UW-Madison, on the Data Challenge hosted by Data Science Club. The task was to preprocess the dataset given and develop best prediction statiscal/ML models possible (‚Äúbest‚Äù means highest accuracy) The dataset came from Kaggle.com, about predicting death due to heart failure based on twelve health characteristics on almost 300 patients (diabetes, high blood pressure, etc.). We applied Logistic Regression and Random Forest, with the latter achieving 87% at the end. For model evaluation, we used confusion matrix and ROC curve. Finally, we did an analysis report and presented our findings to professors and other teams. ","date":"2020-11-05","objectID":"/data_challenge_2020/:1:0","tags":["machine learning","statistics","data analysis","Python"],"title":"Heart Failure Death Prediction Project in Data Challenge 2020","uri":"/data_challenge_2020/"},{"categories":["projects"],"content":"2.Final results deliverables üëâ colab code üëâ analysis report slides ","date":"2020-11-05","objectID":"/data_challenge_2020/:2:0","tags":["machine learning","statistics","data analysis","Python"],"title":"Heart Failure Death Prediction Project in Data Challenge 2020","uri":"/data_challenge_2020/"},{"categories":["blogs"],"content":"Use Google Colab and gspread, a Python API for Google Sheets, to update my Pomodoro Tracker","date":"2022-01-14","objectID":"/pomodoro/","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"Stuggling with time management for the past semester, I came across the Pomodoro Technique developed by Francesco Cirillo. Although it was something I‚Äôve heard of a long time ago, I still decided to give it a try. This time I used Google Sheets as my Pomodoro tracker. I have divided the tracker to 3 sheets, they are (1) Today‚Äôs To-Do, (2) Daily Log, and (3) To-Dos (See below images). I would use To-Dos to record my general goals I wanna accomplish either in short run or long run. Then, at the beginning of each day, I pick some tasks I would like to focus on and put those to Today‚Äôs To-Do; at the end of each day, I manually enter today‚Äôs finished tasks and organize them into Daily Log, which is an extensive table that recorded what I did each date. Today's To-Do\u003cimg src=\"Daily-To-Do.png\" width=\"250\"/\u003e \" Today's To-Do Daily Log\u003cimg src=\"Daily-log.png\" width=\"250\"/\u003e \" Daily Log To-Dos\u003cimg src=\"To-Dos.png\" width=\"250\"/\u003e \" To-Dos After manually transferring information from Today‚Äôs To-Do to Daily Log for a while, I got tired of the tedious ‚Äúcopy and paste‚Äù process. Thinking it might be a good chance to pick up some new skills, I looked up how to read and write Google Sheets using the elegant gspread API and it turned out to save so much time by just running a short script. ","date":"2022-01-14","objectID":"/pomodoro/:0:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"Demo Files (Follow along!) If you want to get a hands-on experience, you can use the demo files to code along with me. You are welcome to adapt and improve to make your own fit. populate log.ipynb: Python script Pomodoro Technique Google Sheets ","date":"2022-01-14","objectID":"/pomodoro/:1:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"1. Imports import pandas as pd from google.colab import auth import gspread from oauth2client.client import GoogleCredentials from datetime import date, datetime import pytz import os import json ","date":"2022-01-14","objectID":"/pomodoro/:2:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"2. Authenticate and Authorize auth.authenticate_user() gc = gspread.authorize(GoogleCredentials.get_application_default()) The first step is to enable Google Sheets API to access your spreadsheets. ‚ÄúAuthentication and authorization are mechanisms used to verify identity and access to resources, respectively.‚Äù You can learn more about authentication and authorization here. But essentially, once you run these two lines of code, an URL will pop up and opens a new tab in your browser which requires you to grant access. After that, copy the url and paste that to the box says verification. ","date":"2022-01-14","objectID":"/pomodoro/:3:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"3. Retrieve your sheets url = \"https://docs.google.com/spreadsheets/d/1oogWtA5vSlcZTYzYL1CDrv4FIytao2MBBq6UmCKHLK4/edit#gid=0\" wb = gc.open_by_url(url) todosheet = wb.worksheet(\"Today's To-Do\") logsheet = wb.worksheet(\"Daily Log\") Next we‚Äôre very much prepared to open our spreadsheets. Remember the gc variable above, which stores a client_class instance which you don‚Äôt really need to know. gc.open_by_url(url) opens a spreadhsheet by url and returns a Spreadsheet instance wb. By changing the name parameter of wb.worksheet(???), we can retrieve our respective sheets. ","date":"2022-01-14","objectID":"/pomodoro/:4:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"4. Manipulate retrieved sheets data In my case, because I want to read the cell data into list of lists (which represent rows) and write it to a new sheet, I have manipulated it in ways I see fit. The returned newList will be used to populate the ‚ÄúDaily Log‚Äù sheet. data = todosheet.get_all_values() df_todo = pd.DataFrame(data) df_todo.columns = df_todo.iloc[0] df_todo = df_todo.drop(0) df_todo = df_todo.reset_index(drop=True) header = df_todo.columns.tolist() rowsList = df_todo.to_numpy().tolist() ''' return a list of lists to populate the log sheet will only add tasks that have already been done ''' def createPopulateData(rowsList): newList = [] for row in rowsList: rowList = [] task = row[header.index('task')] status = row[header.index('status')] if task == \"\" or status == \"\": break start_time = row[header.index('start time')] stepType = row[header.index('step/type')] pomos = row[header.index('pomodoro(s)')] pomoNum, intDistract, extDistract = 0, 0, 0 for sign in pomos: if sign == \"x\": pomoNum += 1 elif sign == \"-\": extDistract += 1 elif sign == \"'\": intDistract += 1 else: continue if pomoNum == 0: continue tz = pytz.timezone(\"US/Central\") todayDate = datetime.now(tz).strftime(\"%m/%d/%y\") # assumes the author runs the script before local 11:59 pm notes = row[header.index('notes')] rowList.extend([todayDate, start_time, stepType, task, pomoNum, intDistract, extDistract, notes]) newList.append(rowList) return newList newList = createPopulateData(rowsList) ","date":"2022-01-14","objectID":"/pomodoro/:5:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"5. Streamline the update process What if I wish to rewrite because I have made some other modifications to my ‚ÄúToday‚Äôs To-Do‚Äù sheet since my last write? Because the sheet.append_rows() function by default appends after the last filled row of the table and I don‚Äôt want that, I create a marks.json file when I run the script initially, which records the starting index of the range and whether this is an update action. If it‚Äôs an update action, I will switch to using sheet.update() as it will update and reflect the new changes I‚Äôve made to sheet. path = \"/content/marks.json\" if not os.path.exists(path): start = len(logsheet.col_values(1)) + 1 marks = {} marks[\"start\"] = start marks[\"update\"] = False with open(path, \"w\") as f: json.dump(marks, f) else: with open(path) as f1: marks = json.load(f1) marks[\"update\"] = True with open(path, \"w\") as f2: json.dump(marks, f2) with open(path) as f: marks = json.load(f) start, update = marks[\"start\"], marks[\"update\"] ''' do not delete Today's To-Do sheet until satisfied with Daily log editing because starting index of rows range to append is fixed ''' append = len(newList) - 1 end = marks[\"start\"] + append if not update: print(f\"append {len(newList)} rows to Daily Log\") res = logsheet.append_rows(newList, table_range=f\"A{start}:H{end}\") else: print(f\"update {len(newList)} rows to Daily Log\") res = logsheet.update(f\"A{start}:H{end}\", newList) if len(newList) == 0: print(\"no finished task to append or update yet :)\") res Lastly, the res object includes an automatic response that tells what has been appended or updated, to confirm if we do the right thing. ","date":"2022-01-14","objectID":"/pomodoro/:6:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"Take some time to refresh my understanding towards `p-value` and keep a note here.","date":"2020-09-01","objectID":"/stats_pvalue/","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on P-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"I feel this topic is rather important and worthy to dive into as 3 out of my 4 courses this semester have covered this concept. Yet having learned p-value and hypothesis testing on my AP course early since high school and my college introductory stats course, it always remains a bit foggy. Thus, it would be good to review for learning consolidation and future reference. ","date":"2020-09-01","objectID":"/stats_pvalue/:0:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on P-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"1. What does it actually mean to reject the null? Rejecting null doesn‚Äôt mean it‚Äôs true, it just means we fail to prove it‚Äôs false. $H_{0}$ and $H_{1}$ are not the opposites. It‚Äôs not like one way or the other. Assume null is true, there has happend a low probability event. It seems too rare to happen but if it does happen, then it‚Äôs reasonable to suspect the validity of the null. ","date":"2020-09-01","objectID":"/stats_pvalue/:1:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on P-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"2. Hypothesis testing According to Wooldrige‚Äôs textbook: there‚Äôre two approaches. classical: compare critical value with test statistic, if test statistic \u003e critical value, then reject, because we get a sufficiently large value compared to the null. note as $\\alpha$ significance level decreases, the critical value increases, which means it becomes harder to reject the null and one needs larger test statistic for rejection. For example, if I can reject the null at 5 % significance level, I can surely reject it at 10%. p-value: calculate p-value and compare it to sigficance level, if p-value \u003c significance level, reject the null, vice versa. ","date":"2020-09-01","objectID":"/stats_pvalue/:2:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on P-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"3. Additional thoughts Given the observed value of the t statistic, p value is the smallest significance level (alpha) at which the null hypothesis would be rejected. ‚Äì Cited from Wooldrige To put it in my own understanding, if p-value is 0.03, it means we would observe test statistic as extreme 3% of time when null is true. Smaller p means stronger evidence against $H_{0}$. To compare it with $\\alpha$ the signficance level is to make sure if we were to reject the null 3% of time, it should be within the tolerance of error(the significance level), say if $\\alpha$ is 0.05, we‚Äôre willing to accept mistakenly reject the null 5% of time when it is actually true. Why say p-value is the smallest significance level? if we calculate p to be 0.03 and we can reject the null at 3% significance level, we can certainly reject this at 5% if set by the question. ","date":"2020-09-01","objectID":"/stats_pvalue/:3:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on P-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["projects"],"content":"Build custom functions from Google Apps Script to format my data entry form and extract useful information from data","date":"2022-03-14","objectID":"/gs_transaction_format/","tags":["Google Apps Script","Google Sheets","Speadsheet","data analysis"],"title":"Use Google Apps Script to Streamline My Transaction Recording","uri":"/gs_transaction_format/"},{"categories":["projects"],"content":"Money-borrowing happen almost every second, especially between friends. Today I want to talk about how to facilitate our repayment process so that the minimum transactions can be done. Specifically, here is a google sheet demo I have created to imitate money-borrowing between, say 6 friends. Raw Transaction Sheet\u003cimg src=\"raw_transaction.png\" width=\"250\"/\u003e \" Raw Transaction Sheet The first thing that comes into my mind is that the format could have a bit extra work. The second thing is that whether we could automate to extract a ‚Äúowed money‚Äù matrix so that everyone knows exactly how much they need to pay back to the other person? It particularly annoys me where I need to go back and forth to click through buttons to reformat ,and the automation is best done with assistance of programming tool. That is when Google Apps Script comes into my mind! It can help build web applications that perfectly blends into Google Spreadsheet and ease our lives. The final formatting product looks like this: Formatted Transaction Sheet\u003cimg src=\"formatted_transaction.png\" width=\"250\"/\u003e \" Formatted Transaction Sheet The ‚Äúowed money‚Äù or ‚Äúdebt‚Äù matrix looks like this: Debt Matrix\u003cimg src=\"debt_matrix.png\" width=\"250\"/\u003e \" Debt Matrix You can see clearly that now Andy still needs to pay back $$6.03$ to Sarah! Although Andy did once lend $$7.83$ to Sarah, later Sarah lended another $$13.86$ to Andy. Instead of two transactions where Sarah returns $$7.83$ to Andy and Andy returns $$13.86$ to Sarah, only one transaction can do the job! This is just a small demo. The application needs more optimization for sure. Stay tuned! ","date":"2022-03-14","objectID":"/gs_transaction_format/:0:0","tags":["Google Apps Script","Google Sheets","Speadsheet","data analysis"],"title":"Use Google Apps Script to Streamline My Transaction Recording","uri":"/gs_transaction_format/"},{"categories":["projects"],"content":"Demo Files If you want to get a hands-on experience, you can try out the demo files. You are welcome to adapt and improve to make your own fit. There are three sheets called transaction, personal info, and debt matrix under spreadsheet Copy of transaction app. You can ignore the personal info one, which I originally intend to make an automated email app to remind debters. (will do in the future!) Copy of transaction app ","date":"2022-03-14","objectID":"/gs_transaction_format/:1:0","tags":["Google Apps Script","Google Sheets","Speadsheet","data analysis"],"title":"Use Google Apps Script to Streamline My Transaction Recording","uri":"/gs_transaction_format/"},{"categories":["projects"],"content":"1. Resources \u0026 References! I referred to some resources which I found particularly useful: Google Apps Script Tutorial for Beginners (My format function definitely refers to this! Special thanks for the inspiration.) Google Apps Script Documentation: Spreadsheet stackoverflow (recommended!) ","date":"2022-03-14","objectID":"/gs_transaction_format/:2:0","tags":["Google Apps Script","Google Sheets","Speadsheet","data analysis"],"title":"Use Google Apps Script to Streamline My Transaction Recording","uri":"/gs_transaction_format/"},{"categories":["projects"],"content":"2. Instructions Dropdown functions\u003cimg src=\"show_dropdown.png\" width=\"250\"/\u003e \" Dropdown functions If you click the Custom Functions in the top menu bar, you will see these four functions. Format Sheet is what you can apply to any of the three sheets. It will apply the same formatting to all except the debt matrix, which needs different handling regarding its left and top side. Clear Everything is to clear both format and content, so essentially swipe off everything. Clear Format, as its name suggests, clears only the format but preserves the content. Fill Table is intended to be applied to the last sheet: debt matrix. It updates the table in whole every time you run it to matches with the data in transaction table. To achieve the intended effect of the above debt matrix, you need to run Fill Table first and then Format Sheet. Also, for the firs time you apply any of the function, script will ask for permission to access your personal account. After allowing, you will be good to go! ","date":"2022-03-14","objectID":"/gs_transaction_format/:3:0","tags":["Google Apps Script","Google Sheets","Speadsheet","data analysis"],"title":"Use Google Apps Script to Streamline My Transaction Recording","uri":"/gs_transaction_format/"},{"categories":["blogs"],"content":"A blog that shares some of my own experiences with building Hugo website.","date":"2021-11-10","objectID":"/hugo_tutorial/","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"1. Requirements install git install hugo ","date":"2021-11-10","objectID":"/hugo_tutorial/:1:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"2. Get started I would suggest look over official documentations for basic installation and configuration. If you cannot solve problem by then, check out blog posts that might be helpful. ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"docs https://hugoloveit.com/ (site demo) https://gohugo.io/getting-started/quick-start/ https://hugoloveit.com/ (this is the LoveIt theme in Hugo, but format\u0026troubleshoot should generalize to other templates) YouTube tutorial step by step ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:1","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"blogs is-there-a-place-we-can-put-non-blog-files-pdf-files-in-blogdown how-to-make-a-mulilingual-website-with-hugo ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:2","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"misc Font_Awesome.docset (icons) Common Issues If your page under development mode crashed, be patient and maybe reload the server in terminal with Ctrl-C and hugo server -D Be careful about syntax, format, especially with multilingual setting. If you‚Äôre not sure the organization, always refer to the themes/xxx(LoveIt)/exampleSite folder first that‚Äôs contained in every Hugo repo after you clone it. When you want to add the featured image for the content preview in the home page, do: resources: - name: \"featured-image\" src: \"featured-image.png\" and name your md file to be index.md. Don‚Äôt forget to add the \u003c!--more--\u003e divider if you want to tell Hugo only summarizes the content before divider in preview. ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:3","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"3. Publish your page Publishing the page is a bit of hassle for me. My sincere suggestion after this experience is to find a tutorial and closely follow the steps. Even if you don‚Äôt like the theme or the tutorial style, it‚Äôs always easier to build up your understanding first and level up/optimize from there. I used GitHub to host my website and here is a list of docs/blogs that I referred to: https://hongtaoh.com/en/2021/04/05/hugo-deploy-github-actions/ https://gohugo.io/hosting-and-deployment/hosting-on-github/ https://levelup.gitconnected.com/build-a-personal-website-with-github-pages-and-hugo-6c68592204c7 https://www.pluralsight.com/guides/how-to-host-your-static-webpages-on-github-pages ","date":"2021-11-10","objectID":"/hugo_tutorial/:3:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"4. Other details ","date":"2021-11-10","objectID":"/hugo_tutorial/:4:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"comment To set up utterances comment section, I updated both config.toml and installed utterances app to repo. There are other alternatives like Disqus and Valine. ","date":"2021-11-10","objectID":"/hugo_tutorial/:4:1","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"gdocs shortcodes Thanks to Ashish Tiwari‚Äôs shortcodes post and wowchemy-hugo-modules, I‚Äôm able to incorporate the gdocs shortcodes functionality. In particular, be aware in your shortcodes {{\u003cgdocs src=\"???\"\u003e}} , the src url should be the one published to web (in your google slides, go to File and then Publish to the web, select either link or embed and copy the url in src=\"???\"), not the shared url. I corrected this once I found only my laptop web can show gdocs (also the display is not very satisfactory) while ipad and iphone can‚Äôt. Specifial thanks to Cecina Babich Morrow‚Äôs post. ","date":"2021-11-10","objectID":"/hugo_tutorial/:4:2","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"My experiences with configuring Matlab into Jupyter Notebook in a remote machine","date":"2022-01-30","objectID":"/matlab_jupyter/","tags":["Matlab","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Matlab into Jupyter Notebook","uri":"/matlab_jupyter/"},{"categories":["blogs"],"content":"I started using Jupyter Notebook only for coding in Python. However, gradually as I learnt more programming languages, I wish I could have all languages in one environment; Then I don‚Äôt need to open multiple programs. Luckily, I was told I could easily configure those languages into the Notebook (though not an easy process for me, /(„Ñío„Ñí)/~~) and as I would be learning both Matlab and Julia this semester, it would be a good chance to try it out. Caveats for those who want to keep on reading, this blog (1) doesn‚Äôt include how to install Matlab either in your own or remote computer (2) is mainly for installing MATLAB Engine API for Python in a remote location (where you don‚Äôt have write permission, in other words, not super user) and troubleshooting as I don‚Äôt want to install Matlab on my own laptop but still want to enjoy the benefits. Though, the process can be adapted and generalized to other cases and I do have references listed below that suit a variety of needs. ","date":"2022-01-30","objectID":"/matlab_jupyter/:0:0","tags":["Matlab","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Matlab into Jupyter Notebook","uri":"/matlab_jupyter/"},{"categories":["blogs"],"content":"0. References You‚Äôre encouraged to try it on your own first. Here‚Äôre some resources (including troubleshoots) I referred to in the process: References List Matlab Kernel for Jupyter Notebooks Tutorial Install MATLAB Engine API for Python in Nondefault Locations Install Jupyter-MATLAB How do I properly install Matlab Engine using the anaconda package manager for Python? PackagesNotFoundError: The following packages are not available from current channels: 404 error and no such comm target when trying to use ipywidgets Most tutorials assume the coders already have a relatively high level of understanding. To a newbie like me, I‚Äôd appreciate more detailed explanation. That‚Äôs also why I immediately write this blog, for my own reference and for those stuggling with getting it right. ","date":"2022-01-30","objectID":"/matlab_jupyter/:1:0","tags":["Matlab","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Matlab into Jupyter Notebook","uri":"/matlab_jupyter/"},{"categories":["blogs"],"content":"1. Create myenv using Conda I would suggest for this type of task to always create an virtual environment. Then you can personalize any setting and packages in case the task doesn‚Äôt align with packages installed in the base or you don‚Äôt want to mess with that. The prerequisite is that you should install conda through either Miniconda or Anaconda. I highly regretted not doing this at the beginning because later during one step I found out for some reasons Python 3.8 doesn‚Äôt work very well; so I ended up switching to Python 3.7 when I create myenv susu: conda create -n susu python=3.7 For more conda create env related stuff, please check out the documentation linked here. ","date":"2022-01-30","objectID":"/matlab_jupyter/:2:0","tags":["Matlab","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Matlab into Jupyter Notebook","uri":"/matlab_jupyter/"},{"categories":["blogs"],"content":"2. Find your MATLAB Folder matlabroot Ideally, matlabroot can be found by opening the installed Matlab App and run matlabroot. You will see a path like ans = \"???/???/matlab-2021b\". But what do you do when the remote computer is not near you? Then you can ssh to that machine and work around this in terminal, which tends to be slow. You can speed it up (though not much I feel) by opening Matlab in terminal by entering matlab -nodesktop -nodisplay. It starts by saying MATLAB is selecting SOFTWARE OPENGL rendering. That‚Äôs a good sign, and you will just wait for a few minutes. Once \u003e\u003e symbol pops up, run matlabroot. ","date":"2022-01-30","objectID":"/matlab_jupyter/:3:0","tags":["Matlab","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Matlab into Jupyter Notebook","uri":"/matlab_jupyter/"},{"categories":["blogs"],"content":"3. Build or Install in Nondefault Folders Basically, if you do not have write permission to the default Matlab folder and default Python folder (look up default vs non-default folder if you‚Äôre confused) as I do because I‚Äôm accessing a remote machine, do as follows: cd \"matlabroot\\extern\\engines\\python\" python setup.py build --build-base=\"builddir\" install --prefix=\"installdir\" Notice that builddir would be a path to the non-default folder that you create under MATLAB folder (the default folder automatically get created when you initialize Matlab program). So is the installdir. It is a path to the non-default folder in the search path for Python packages. I create it directly under myenv susu ‚Äî ???/yumian/Documents/miniconda/envs/susu\" ","date":"2022-01-30","objectID":"/matlab_jupyter/:4:0","tags":["Matlab","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Matlab into Jupyter Notebook","uri":"/matlab_jupyter/"},{"categories":["blogs"],"content":"4. Install the Matlab Kernel for Jupyter pip/conda install matlab_kernal python -m matlab_kernel install Tip I suggest using conda instead of pip. Just my experience because pip causes some issues at first for me. When running conda install matlab_kernal, if you run into: PackagesNotFoundError: The following packages are not available from current channels: - matlab_kernel Try conda install -c conda-forge matlab_kernel When running python -m matlab_kernel install, if it says permission defined, do what it suggests, add --user at the end. After done with this step, you‚Äôre pretty much ready to launch your jupyter notebook and see Matlab as an option. Before that, Open Python and run import matlab.engine to verify you have this module correctly installed. Another thing you can do is pip list | grep matlab, which should list something like: matlab-kernel 0.16.11 matlabengineforpython R2021b If while you‚Äôre trying to run the cells, the background keeps reporting Matlab engine not installed: error, go back to check your installed directory; it may be you didn‚Äôt install it correctly. If the background says HTTP 404: Not Found (Kernel does not exist: error, try the trick below (c.r. @tensionhead): jupyter nbextension install --py widgetsnbextension --user jupyter nbextension enable --py widgetsnbextension Happy coding! I will have another blog about configuring Julia which is so much easier than this. (updated: check out the blog about Julia!) ","date":"2022-01-30","objectID":"/matlab_jupyter/:5:0","tags":["Matlab","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Matlab into Jupyter Notebook","uri":"/matlab_jupyter/"},{"categories":["blogs"],"content":"My experiences with configuring Julia into Jupyter Notebook in a remote machine","date":"2022-01-30","objectID":"/julia_jupyter/","tags":["Julia","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Julia into Jupyter Notebook","uri":"/julia_jupyter/"},{"categories":["blogs"],"content":"This blog is written soon after my Configure Matlab into Jupyter Notebook blog. If you‚Äôd like to see that one, you can click here. It is easier to install so let‚Äôs just get started! ","date":"2022-01-30","objectID":"/julia_jupyter/:0:0","tags":["Julia","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Julia into Jupyter Notebook","uri":"/julia_jupyter/"},{"categories":["blogs"],"content":"0. References Similarly, I post the resources articles I referred in here in case you want to try it on your own. References List Platform Specific Instructions for Official Binaries How to Add Julia to Jupyter Notebook ","date":"2022-01-30","objectID":"/julia_jupyter/:1:0","tags":["Julia","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Julia into Jupyter Notebook","uri":"/julia_jupyter/"},{"categories":["blogs"],"content":"1. Download Julia There‚Äôs no Julia installed in the remote machine. Please take a look at the first document in list to find the instructions tailored to your computer type ‚Äî Windows, MaxOS, or Linux. I‚Äôm on Linux, so I jumped to the section Linux and FreeBSD. wget https://julialang-s3.julialang.org/bin/linux/x64/1.7/julia-1.7.1-linux-x86_64.tar.gz tar zxvf julia-1.7.1-linux-x86_64.tar.gz Remember to add Julia‚Äôs bin folder to PATH environmental variable so that you can execute Julia anywhere. Otherwise, you need to do \u003cJulia directory\u003e/bin/julia every time. vim ~/.bashrc export PATH=\"$PATH:/path/to/\u003cJulia directory\u003e/bin\" / export PATH=\"/path/to/\u003cJulia directory\u003e/bin:$PATH\" source ~/.bashrc # Don't forget! Start a new terminal and try go to a folder that‚Äôs not Julia‚Äôs bin, enter julia, which should work just fine. You will see julia\u003e command line. ","date":"2022-01-30","objectID":"/julia_jupyter/:2:0","tags":["Julia","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Julia into Jupyter Notebook","uri":"/julia_jupyter/"},{"categories":["blogs"],"content":"2. Add Julia to Jupyter Notebook Now in the new terminal where you just opened Julia, do: using Pkg Pkg.add(\"IJulia\") Done! Now open a new jupyter notebook and you should see Julia as an option in your notebook drop-down menu. ","date":"2022-01-30","objectID":"/julia_jupyter/:3:0","tags":["Julia","Jupyter Notebook","Python","configuration","installation"],"title":"Configure Julia into Jupyter Notebook","uri":"/julia_jupyter/"},{"categories":null,"content":" Thanks for visiting! This website will soon be added my old posts and updated periodically in the future.Please click here to view my latest CV. If you have any thoughts about my website or its contents or just anything in general, please don‚Äôt hesitate to contact me! May 2020 at Wisconsin State Capitolc.r. Yizhou Lu \" May 2020 at Wisconsin State Capitol ","date":"2021-11-21","objectID":"/about/:0:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"About me My name is Yumian Cui, and I come from China. My pronouns are she/her/hers. I‚Äôm currently a senior undergrad at UW-Madison, studying Data Science and Economics (Math emphasis) with a certificate in Computer Science. Before college, I completed all my education in China. ","date":"2021-11-21","objectID":"/about/:0:1","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"Interests ¬†reading ¬†tutoring ¬†coding ¬†eating ¬†listening to music ¬†playing with my cats Research Interests ¬†Machine Learning ¬†Human Computer Interaction (HCI) ¬†Natural Language Processing (NLP) ","date":"2021-11-21","objectID":"/about/:0:2","tags":null,"title":"About Me","uri":"/about/"}]