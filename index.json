[{"categories":["blogs"],"content":"Use Google Colab and gspread, a Python API for Google Sheets, to update my Pomodoro Tracker","date":"2022-01-14","objectID":"/pomodoro/","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"Stuggling with time management for the past semester, I came across the Pomodoro Technique developed by Francesco Cirillo. Although it was something I’ve heard of a long time ago, I still decided to give it a try. This time I used Google Sheets as my Pomodoro tracker. I have divided the tracker to 3 sheets, they are (1) Today’s To-Do, (2) Daily Log, and (3) To-Dos (See below images). I would use To-Dos to record my general goals I wanna accomplish either in short run or long run. Then, at the beginning of each day, I pick some tasks I would like to focus on and put those to Today’s To-Do; at the end of each day, I manually enter today’s finished tasks and organize them into Daily Log, which is an extensive table that recorded what I did each date. Today's To-Do\u003cimg src=\"Daily-To-Do.png\" width=\"250\"/\u003e \" Today's To-Do Daily Log\u003cimg src=\"Daily-log.png\" width=\"250\"/\u003e \" Daily Log To-Dos\u003cimg src=\"To-Dos.png\" width=\"250\"/\u003e \" To-Dos After manually transferring information from Today’s To-Do to Daily Log for a while, I got tired of the tedious “copy and paste” process. Thinking it might be a good chance to pick up some new skills, I looked up how to read and write Google Sheets using the elegant gspread API and it turned out to save so much time by just running a short script. ","date":"2022-01-14","objectID":"/pomodoro/:0:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"Demo Files (Follow along!) If you want to get a hands-on experience, you can use the demo files to code along with me. You are welcome to adapt and improve to make your own fit. populate log.ipynb: Python script Pomodoro Technique Google Sheets ","date":"2022-01-14","objectID":"/pomodoro/:1:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"1. Imports import pandas as pd from google.colab import auth import gspread from oauth2client.client import GoogleCredentials from datetime import date, datetime import pytz import os import json ","date":"2022-01-14","objectID":"/pomodoro/:2:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"2. Authenticate and Authorize auth.authenticate_user() gc = gspread.authorize(GoogleCredentials.get_application_default()) The first step is to enable Google Sheets API to access your spreadsheets. “Authentication and authorization are mechanisms used to verify identity and access to resources, respectively.” You can learn more about authentication and authorization here. But essentially, once you run these two lines of code, an URL will pop up and opens a new tab in your browser which requires you to grant access. After that, copy the url and paste that to the box says verification. ","date":"2022-01-14","objectID":"/pomodoro/:3:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"3. Retrieve your sheets url = \"https://docs.google.com/spreadsheets/d/1oogWtA5vSlcZTYzYL1CDrv4FIytao2MBBq6UmCKHLK4/edit#gid=0\" wb = gc.open_by_url(url) todosheet = wb.worksheet(\"Today's To-Do\") logsheet = wb.worksheet(\"Daily Log\") Next we’re very much prepared to open our spreadsheets. Remember the gc variable above, which stores a client_class instance which you don’t really need to know. gc.open_by_url(url) opens a spreadhsheet by url and returns a Spreadsheet instance wb. By changing the name parameter of wb.worksheet(???), we can retrieve our respective sheets. ","date":"2022-01-14","objectID":"/pomodoro/:4:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"4. Manipulate retrieved sheets data In my case, because I want to read the cell data into list of lists (which represent rows) and write it to a new sheet, I have manipulated it in ways I see fit. The returned newList will be used to populate the “Daily Log” sheet. data = todosheet.get_all_values() df_todo = pd.DataFrame(data) df_todo.columns = df_todo.iloc[0] df_todo = df_todo.drop(0) df_todo = df_todo.reset_index(drop=True) header = df_todo.columns.tolist() rowsList = df_todo.to_numpy().tolist() ''' return a list of lists to populate the log sheet will only add tasks that have already been done ''' def createPopulateData(rowsList): newList = [] for row in rowsList: rowList = [] task = row[header.index('task')] status = row[header.index('status')] if task == \"\" or status == \"\": break start_time = row[header.index('start time')] stepType = row[header.index('step/type')] pomos = row[header.index('pomodoro(s)')] pomoNum, intDistract, extDistract = 0, 0, 0 for sign in pomos: if sign == \"x\": pomoNum += 1 elif sign == \"-\": extDistract += 1 elif sign == \"'\": intDistract += 1 else: continue if pomoNum == 0: continue tz = pytz.timezone(\"US/Central\") todayDate = datetime.now(tz).strftime(\"%m/%d/%y\") # assumes the author runs the script before local 11:59 pm notes = row[header.index('notes')] rowList.extend([todayDate, start_time, stepType, task, pomoNum, intDistract, extDistract, notes]) newList.append(rowList) return newList newList = createPopulateData(rowsList) ","date":"2022-01-14","objectID":"/pomodoro/:5:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"5. Streamline the update process What if I wish to rewrite because I have made some other modifications to my “Today’s To-Do” sheet since my last write? Because the sheet.append_rows() function by default appends after the last filled row of the table and I don’t want that, I create a marks.json file when I run the script initially, which records the starting index of the range and whether this is an update action. If it’s an update action, I will switch to using sheet.update() as it will update and reflect the new changes I’ve made to sheet. path = \"/content/marks.json\" if not os.path.exists(path): start = len(logsheet.col_values(1)) + 1 marks = {} marks[\"start\"] = start marks[\"update\"] = False with open(path, \"w\") as f: json.dump(marks, f) else: with open(path) as f1: marks = json.load(f1) marks[\"update\"] = True with open(path, \"w\") as f2: json.dump(marks, f2) with open(path) as f: marks = json.load(f) start, update = marks[\"start\"], marks[\"update\"] ''' do not delete Today's To-Do sheet until satisfied with Daily log editing because starting index of rows range to append is fixed ''' append = len(newList) - 1 end = marks[\"start\"] + append if not update: print(f\"append {len(newList)} rows to Daily Log\") res = logsheet.append_rows(newList, table_range=f\"A{start}:H{end}\") else: print(f\"update {len(newList)} rows to Daily Log\") res = logsheet.update(f\"A{start}:H{end}\", newList) if len(newList) == 0: print(\"no finished task to append or update yet :)\") res Lastly, the res object includes an automatic response that tells what has been appended or updated, to confirm if we do the right thing. ","date":"2022-01-14","objectID":"/pomodoro/:6:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"Two Seconds to Populate My Pomodoro Tracker by Google Sheets API","uri":"/pomodoro/"},{"categories":["blogs"],"content":"A blog that shares some of my own experiences with building Hugo website.","date":"2021-11-10","objectID":"/hugo_tutorial/","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"1. Requirements install git install hugo ","date":"2021-11-10","objectID":"/hugo_tutorial/:1:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"2. Get started I would suggest look over official documentations for basic installation and configuration. If you cannot solve problem by then, check out blog posts that might be helpful. ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"docs https://hugoloveit.com/ (site demo) https://gohugo.io/getting-started/quick-start/ https://hugoloveit.com/ (this is the LoveIt theme in Hugo, but format\u0026troubleshoot should generalize to other templates) YouTube tutorial step by step ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:1","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"blogs is-there-a-place-we-can-put-non-blog-files-pdf-files-in-blogdown how-to-make-a-mulilingual-website-with-hugo ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:2","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"misc Font_Awesome.docset (icons) Common Issues If your page under development mode crashed, be patient and maybe reload the server in terminal with Ctrl-C and hugo server -D Be careful about syntax, format, especially with multilingual setting. If you’re not sure the organization, always refer to the themes/xxx(LoveIt)/exampleSite folder first that’s contained in every Hugo repo after you clone it. When you want to add the featured image for the content preview in the home page, do: resources: - name: \"featured-image\" src: \"featured-image.png\" and name your md file to be index.md. Don’t forget to add the \u003c!--more--\u003e divider if you want to tell Hugo only summarizes the content before divider in preview. ","date":"2021-11-10","objectID":"/hugo_tutorial/:2:3","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"3. Publish your page Publishing the page is a bit of hassle for me. My sincere suggestion after this experience is to find a tutorial and closely follow the steps. Even if you don’t like the theme or the tutorial style, it’s always easier to build up your understanding first and level up/optimize from there. I used GitHub to host my website and here is a list of docs/blogs that I referred to: https://hongtaoh.com/en/2021/04/05/hugo-deploy-github-actions/ https://gohugo.io/hosting-and-deployment/hosting-on-github/ https://levelup.gitconnected.com/build-a-personal-website-with-github-pages-and-hugo-6c68592204c7 https://www.pluralsight.com/guides/how-to-host-your-static-webpages-on-github-pages ","date":"2021-11-10","objectID":"/hugo_tutorial/:3:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"4. Other details ","date":"2021-11-10","objectID":"/hugo_tutorial/:4:0","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"comment To set up utterances comment section, I updated both config.toml and installed utterances app to repo. There are other alternatives like Disqus and Valine. ","date":"2021-11-10","objectID":"/hugo_tutorial/:4:1","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"gdocs shortcodes Thanks to Ashish Tiwari’s shortcodes post and wowchemy-hugo-modules, I’m able to incorporate the gdocs shortcodes functionality. In particular, be aware in your shortcodes {{\u003cgdocs src=\"???\"\u003e}} , the src url should be the one published to web (in your google slides, go to File and then Publish to the web, select either link or embed and copy the url in src=\"???\"), not the shared url. I corrected this once I found only my laptop web can show gdocs (also the display is not very satisfactory) while ipad and iphone can’t. Specifial thanks to Cecina Babich Morrow’s post. ","date":"2021-11-10","objectID":"/hugo_tutorial/:4:2","tags":["installation","configuration","website"],"title":"Build your Hugo website","uri":"/hugo_tutorial/"},{"categories":["blogs"],"content":"Take some time to refresh my understanding towards `p-value` and keep a note here.","date":"2020-09-01","objectID":"/stats_pvalue/","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on p-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"I feel this topic is rather important and worthy to dive into as 3 out of my 4 courses this semester have covered this concept. Yet having learned p-value and hypothesis testing on my AP course early since high school and my college introductory stats course, it always remains a bit foggy. Thus, it would be good to review for learning consolidation and future reference. ","date":"2020-09-01","objectID":"/stats_pvalue/:0:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on p-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"1. What does it actually mean to reject the null? Rejecting null doesn’t mean it’s true, it just means we fail to prove it’s false. $H_{0}$ and $H_{1}$ are not the opposites. It’s not like one way or the other. Assume null is true, there has happend a low probability event. It seems too rare to happen but if it does happen, then it’s reasonable to suspect the validity of the null. ","date":"2020-09-01","objectID":"/stats_pvalue/:1:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on p-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"2. Hypothesis testing According to Wooldrige’s textbook: there’re two approaches. classical: compare critical value with test statistic, if test statistic \u003e critical value, then reject, because we get a sufficiently large value compared to the null. note as $\\alpha$ significance level decreases, the critical value increases, which means it becomes harder to reject the null and one needs larger test statistic for rejection. For example, if I can reject the null at 5 % significance level, I can surely reject it at 10%. p-value: calculate p-value and compare it to sigficance level, if p-value \u003c significance level, reject the null, vice versa. ","date":"2020-09-01","objectID":"/stats_pvalue/:2:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on p-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["blogs"],"content":"3. Additional thoughts Given the observed value of the t statistic, p value is the smallest significance level (alpha) at which the null hypothesis would be rejected. – Cited from Wooldrige To put it in my own understanding, if p-value is 0.03, it means we would observe test statistic as extreme 3% of time when null is true. Smaller p means stronger evidence against $H_{0}$. To compare it with $\\alpha$ the signficance level is to make sure if we were to reject the null 3% of time, it should be within the tolerance of error(the significance level), say if $\\alpha$ is 0.05, we’re willing to accept mistakenly reject the null 5% of time when it is actually true. Why say p-value is the smallest significance level? if we calculate p to be 0.03 and we can reject the null at 3% significance level, we can certainly reject this at 5% if set by the question. ","date":"2020-09-01","objectID":"/stats_pvalue/:3:0","tags":["p-value","statistics","hypothesis testing"],"title":"Reflection on p-value in Hypothesis Testing","uri":"/stats_pvalue/"},{"categories":["projects"],"content":"An overview of my work in Data Challenge hosted by UW-Madison Data Science Club","date":"2020-11-05","objectID":"/data_challenge_2020/","tags":["machine learning","statistics","data analysis","Python"],"title":"Heart failure death prediction project in Data Challenge 2020","uri":"/data_challenge_2020/"},{"categories":["projects"],"content":"1.What I did In Junior Fall 2020, I collaborated with Shaonan Wang, an ISYE major at UW-Madison, on the Data Challenge hosted by Data Science Club. The task was to preprocess the dataset given and develop best prediction statiscal/ML models possible (“best” means highest accuracy) The dataset came from Kaggle.com, about predicting death due to heart failure based on twelve health characteristics on almost 300 patients (diabetes, high blood pressure, etc.). We applied Logistic Regression and Random Forest, with the latter achieving 87% at the end. For model evaluation, we used confusion matrix and ROC curve. Finally, we did an analysis report and presented our findings to professors and other teams. ","date":"2020-11-05","objectID":"/data_challenge_2020/:1:0","tags":["machine learning","statistics","data analysis","Python"],"title":"Heart failure death prediction project in Data Challenge 2020","uri":"/data_challenge_2020/"},{"categories":["projects"],"content":"2.Final results deliverables 👉 colab code 👉 analysis report slides ","date":"2020-11-05","objectID":"/data_challenge_2020/:2:0","tags":["machine learning","statistics","data analysis","Python"],"title":"Heart failure death prediction project in Data Challenge 2020","uri":"/data_challenge_2020/"},{"categories":["projects"],"content":"Independent project via Python in Summer 2020 EconEx externship","date":"2020-08-09","objectID":"/covid19_analysis/","tags":["Python","data analysis"],"title":"NYC under Covid-19: An analysis on consumer and retail trends","uri":"/covid19_analysis/"},{"categories":["projects"],"content":"1. What I did In Summer 2020, I was fortunate to be selected into the EconEx externship program hosted by Econ department. Mentored by UW-Alumni and Data Scientist Micah Lanier, I completed an independent project analyzing New York City consumer and retail trends under Covid-19. Meanwhile, I self-learnt many useful data analysis techniques in Python, like how to use numpy, pandas, matplotlib … interpolation to fill in missing data and web scraping. ","date":"2020-08-09","objectID":"/covid19_analysis/:1:0","tags":["Python","data analysis"],"title":"NYC under Covid-19: An analysis on consumer and retail trends","uri":"/covid19_analysis/"},{"categories":["projects"],"content":"2. Final results For final deliverables, here is the whitepaper and I also made a video presentation: Here is the full code: (I attached it here but they’re also available on github repo) main.py: import pandas as pd import numpy as np from datetime import datetime import matplotlib.pyplot as plt %matplotlib inline df = pd.read_csv(\"us-counties.csv\",parse_dates=True,index_col=0) pd.options.display.max_rows = 10 df = df['20200304':'20200611'] df.reset_index(inplace=True) df t10 = df.groupby('state').sum().sort_values('cases', ascending=False).head(10) t10 = t10.drop(columns='fips') print (t10.index) t10_list = ['New York', 'New Jersey', 'Illinois', 'California', 'Massachusetts', 'Pennsylvania', 'Michigan', 'Texas', 'Florida', 'Louisiana'] t10 t_c = t10['cases'].to_list() t_d = t10['deaths'].to_list() x = np.arange(len(t10.index)) # the label locations width = 0.35 # the width of the bars fig, ax = plt.subplots(figsize=(12,5)) rects1 = ax.bar(x - width/2, t_c, width, label='cases') rects2 = ax.bar(x + width/2, t_d, width, label='deaths') # Add some text for labels, title and custom x-axis tick labels, etc. ax.set_ylabel('number') ax.set_title('Cases and deaths comparison across top 10 states') ax.set_xticks(x) ax.set_xticklabels(t10.index) #ax.set_yticks(y) #ax.set_yticklabels(y) ax.legend() fig.tight_layout() plt.show() # now I have obtained the top 10 states with cases confirmed. Next I want to plot the contrast between # cases and deaths over time for each state. cov19_counties_bystate_cases = pd.Series(df.groupby(['state','date']).cases.sum()) cov19_counties_bystate_deaths = pd.Series(df.groupby(['state','date']).deaths.sum()) cov19_counties_bystate = pd.DataFrame(cov19_counties_bystate_cases) cov19_counties_bystate['deaths'] = cov19_counties_bystate_deaths cov19_counties_bystate_deaths = pd.Series(cov19_counties.groupby(['state','date']).deaths.sum()) cov19_counties_bystate = pd.DataFrame(cov19_counties_bystate_cases) cov19_counties_bystate['deaths'] = cov19_counties_bystate_deaths cov19_counties_bystate from matplotlib.dates import DateFormatter import matplotlib.dates as mdates cov19_counties.date = pd.to_datetime(cov19_counties.date) pp.figure(figsize=(12,12)) for i, state in enumerate(t10.index): pp.subplot(5,2,i+1) #5 rows, 2 columns pp.plot(cov19_counties_bystate.loc[state].cases,label='cases') pp.plot(cov19_counties_bystate.loc[state].deaths,label='deaths') pp.legend() pp.title(state) #pp.xticks(arange(4), calendar.month_name[3:6+1], rotation=45) pp.tight_layout() # drop rows df = cov19_counties_bystate ax = cov19_counties_bystate.loc['New York'].cases.plot.line(figsize=(12,5)) ax = cov19_counties_bystate.loc['New Jersey'].cases.plot.line(figsize=(12,5)) ax = cov19_counties_bystate.loc['Illinois'].cases.plot.line(figsize=(12,5)) #ax = cov19_counties_bystate.loc['California'].cases.plot.line(figsize=(12,5))''' for state in t10.index[:4+1]: ax = cov19_counties_bystate.loc[state].cases.plot.line(figsize=(12,5)) ax.legend(t10.index[:4+1]) pp.title('states cases') for state in t10.index[:4+1]: ax = cov19_counties_bystate.loc[state].deaths.plot.line(figsize=(12,5)) ax.legend(t10.index[:4+1]) pp.title('states deaths') df[df.state == 'New York'] dfc = df[df.state == 'New York'].pivot_table(index = df[df.state == 'New York'].date, values='cases',aggfunc='sum') dfd = df[df.state == 'New York'].pivot_table(index = df[df.state == 'New York'].date, values='deaths',aggfunc='sum') ax = dfc.plot.line(figsize=(12,5),grid=True,rot=True) dfd.plot.line(figsize=(12,5),grid=True,rot=True,ax=ax) ax.set_xlabel(\"New York\") ax.set_ylabel(\"number\") def plotstate(state_name): dfc = df[df.state == state_name].pivot_table(index = df[df.state == state_name].date, values='cases',aggfunc='sum') dfd = df[df.state == state_name].pivot_table(index = df[df.state == state_name].date, values='deaths',aggfunc='sum') ax = dfc.plot.line(figsize=(12,5),grid=True,rot=True) dfd.plot.line(figsize=(12,5),grid=True,rot=True,ax=ax) ax.set_xlabel(state_name) ax.set_","date":"2020-08-09","objectID":"/covid19_analysis/:2:0","tags":["Python","data analysis"],"title":"NYC under Covid-19: An analysis on consumer and retail trends","uri":"/covid19_analysis/"},{"categories":["projects"],"content":"Adapted from Data Science Enthusiast Nagesh's tutorial about writing NN in Python","date":"2020-08-09","objectID":"/ann_part1/","tags":["Python","ANN","Neural Network"],"title":"Write an ANN from Scratch Part I: Perceptron","uri":"/ann_part1/"},{"categories":["projects"],"content":"Please checkout this Github Gist =\u003e To run the Colab just like I did, please go to https://colab.research.google.com/drive/1vcyY0qq-3jpmuG7UHAVEsctV7-WZpe-8?usp=sharing#scrollTo=Fmd55Zzd0Oyj Special thanks to Nagesh’s tutorial which did an excellent job in explaining neural network in simple manners. Click to view part I of the tutorial series. ","date":"2020-08-09","objectID":"/ann_part1/:0:0","tags":["Python","ANN","Neural Network"],"title":"Write an ANN from Scratch Part I: Perceptron","uri":"/ann_part1/"},{"categories":null,"content":" Thanks for visiting! This website will soon be added my old posts and updated periodically in the future.Please click here to view my latest CV. If you have any thoughts about my website or its contents or just anything in general, please don’t hesitate to contact me! May 2020 at Wisconsin State Capitolc.r. Yizhou Lu \" May 2020 at Wisconsin State Capitol ","date":"2021-11-21","objectID":"/about/:0:0","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"About me My name is Yumian Cui, and I come from China. My pronouns are she/her/hers. I’m currently a senior undergrad at UW-Madison, studying Data Science and Economics (Math emphasis) with a certificate in Computer Science. Before college, I completed all my education in China. ","date":"2021-11-21","objectID":"/about/:0:1","tags":null,"title":"About Me","uri":"/about/"},{"categories":null,"content":"Interests  reading  tutoring  coding  eating  listening to music  playing with my cats Research Interests  Machine Learning  Human Computer Interaction (HCI)  Natural Language Processing (NLP) ","date":"2021-11-21","objectID":"/about/:0:2","tags":null,"title":"About Me","uri":"/about/"}]