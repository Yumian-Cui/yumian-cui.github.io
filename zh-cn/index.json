[{"categories":["blogs"],"content":"Use Google Colab and gspread, a Python API for Google Sheets, to update my Pomodoro Tracker","date":"2022-01-14","objectID":"/zh-cn/pomodoro/","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["blogs"],"content":"Stuggling with time management for the past semester, I came across the Pomodoro Technique developed by Francesco Cirillo. Although it was something Iâ€™ve heard of a long time ago, I still decided to give it a try. This time I used Google Sheets as my Pomodoro tracker. I have divided the tracker to 3 sheets, they are (1) Todayâ€™s To-Do, (2) Daily Log, and (3) To-Dos (See below images). I would use To-Dos to record my general goals I wanna accomplish either in short run or long run. Then, at the beginning of each day, I pick some tasks I would like to focus on and put those to Todayâ€™s To-Do; at the end of each day, I manually enter todayâ€™s finished tasks and organize them into Daily Log, which is an extensive table that recorded what I did each date. Today's To-Do\u003cimg src=\"Daily-To-Do.png\" width=\"250\"/\u003e \" Today's To-Do Daily Log\u003cimg src=\"Daily-log.png\" width=\"250\"/\u003e \" Daily Log To-Dos\u003cimg src=\"To-Dos.png\" width=\"250\"/\u003e \" To-Dos After manually transferring information from Todayâ€™s To-Do to Daily Log for a while, I got tired of the tedious â€œcopy and pasteâ€ process. Thinking it might be a good chance to pick up some new skills, I looked up how to read and write Google Sheets using the elegant gspread API and it turned out to save so much time by just running a short script. ","date":"2022-01-14","objectID":"/zh-cn/pomodoro/:0:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["blogs"],"content":"Demo Files (Follow along!) If you want to get a hands-on experience, you can use the demo files to code along with me. You are welcome to adapt and improve to make your own fit. populate log.ipynb: Python script Pomodoro Technique Google Sheets ","date":"2022-01-14","objectID":"/zh-cn/pomodoro/:1:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["blogs"],"content":"1. Imports import pandas as pd from google.colab import auth import gspread from oauth2client.client import GoogleCredentials from datetime import date, datetime import pytz import os import json ","date":"2022-01-14","objectID":"/zh-cn/pomodoro/:2:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["blogs"],"content":"2. Authenticate and Authorize auth.authenticate_user() gc = gspread.authorize(GoogleCredentials.get_application_default()) The first step is to enable Google Sheets API to access your spreadsheets. â€œAuthentication and authorization are mechanisms used to verify identity and access to resources, respectively.â€ You can learn more about authentication and authorization here. But essentially, once you run these two lines of code, an URL will pop up and opens a new tab in your browser which requires you to grant access. After that, copy the url and paste that to the box says verification. ","date":"2022-01-14","objectID":"/zh-cn/pomodoro/:3:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["blogs"],"content":"3. Retrieve your sheets url = \"https://docs.google.com/spreadsheets/d/1oogWtA5vSlcZTYzYL1CDrv4FIytao2MBBq6UmCKHLK4/edit#gid=0\" wb = gc.open_by_url(url) todosheet = wb.worksheet(\"Today's To-Do\") logsheet = wb.worksheet(\"Daily Log\") Next weâ€™re very much prepared to open our spreadsheets. Remember the gc variable above, which stores a client_class instance which you donâ€™t really need to know. gc.open_by_url(url) opens a spreadhsheet by url and returns a Spreadsheet instance wb. By changing the name parameter of wb.worksheet(???), we can retrieve our respective sheets. ","date":"2022-01-14","objectID":"/zh-cn/pomodoro/:4:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["blogs"],"content":"4. Manipulate retrieved sheets data In my case, because I want to read the cell data into list of lists (which represent rows) and write it to a new sheet, I have manipulated it in ways I see fit. The returned newList will be used to populate the â€œDaily Logâ€ sheet. data = todosheet.get_all_values() df_todo = pd.DataFrame(data) df_todo.columns = df_todo.iloc[0] df_todo = df_todo.drop(0) df_todo = df_todo.reset_index(drop=True) header = df_todo.columns.tolist() rowsList = df_todo.to_numpy().tolist() ''' return a list of lists to populate the log sheet will only add tasks that have already been done ''' def createPopulateData(rowsList): newList = [] for row in rowsList: rowList = [] task = row[header.index('task')] status = row[header.index('status')] if task == \"\" or status == \"\": break start_time = row[header.index('start time')] stepType = row[header.index('step/type')] pomos = row[header.index('pomodoro(s)')] pomoNum, intDistract, extDistract = 0, 0, 0 for sign in pomos: if sign == \"x\": pomoNum += 1 elif sign == \"-\": extDistract += 1 elif sign == \"'\": intDistract += 1 else: continue if pomoNum == 0: continue tz = pytz.timezone(\"US/Central\") todayDate = datetime.now(tz).strftime(\"%m/%d/%y\") # assumes the author runs the script before local 11:59 pm notes = row[header.index('notes')] rowList.extend([todayDate, start_time, stepType, task, pomoNum, intDistract, extDistract, notes]) newList.append(rowList) return newList newList = createPopulateData(rowsList) ","date":"2022-01-14","objectID":"/zh-cn/pomodoro/:5:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["blogs"],"content":"5. Streamline the update process What if I wish to rewrite because I have made some other modifications to my â€œTodayâ€™s To-Doâ€ sheet since my last write? Because the sheet.append_rows() function by default appends after the last filled row of the table and I donâ€™t want that, I create a marks.json file when I run the script initially, which records the starting index of the range and whether this is an update action. If itâ€™s an update action, I will switch to using sheet.update() as it will update and reflect the new changes Iâ€™ve made to sheet. path = \"/content/marks.json\" if not os.path.exists(path): start = len(logsheet.col_values(1)) + 1 marks = {} marks[\"start\"] = start marks[\"update\"] = False with open(path, \"w\") as f: json.dump(marks, f) else: with open(path) as f1: marks = json.load(f1) marks[\"update\"] = True with open(path, \"w\") as f2: json.dump(marks, f2) with open(path) as f: marks = json.load(f) start, update = marks[\"start\"], marks[\"update\"] ''' do not delete Today's To-Do sheet until satisfied with Daily log editing because starting index of rows range to append is fixed ''' append = len(newList) - 1 end = marks[\"start\"] + append if not update: res = logsheet.append_rows(newList, table_range=f\"A{start}:H{end}\") else: res = logsheet.update(f\"A{start}:H{end}\", newList) res Lastly, the res object includes an automatic response that tells what has been appended or updated, to confirm if we do the right thing. ","date":"2022-01-14","objectID":"/zh-cn/pomodoro/:6:0","tags":["pomodoro","Python","gspread","Colab","Google Sheets"],"title":"2 seconds to populate my Pomodoro Tracker by Google Sheets API","uri":"/zh-cn/pomodoro/"},{"categories":["ç¬”è®°"],"content":"ä¸€ä¸ªåšå®¢, åˆ†äº«æˆ‘è‡ªå·±æ„å»º Hugo ç½‘ç«™çš„ä¸€äº›ç»éªŒ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"1. Requirements install git install hugo ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:1:0","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"2. Get started I would suggest look over official documentations for basic installation and configuration. If you cannot solve problem by then, check out blog posts that might be helpful. ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:2:0","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"docs https://hugoloveit.com/ (site demo) https://gohugo.io/getting-started/quick-start/ https://hugoloveit.com/ (this is the LoveIt theme in Hugo, but format\u0026troubleshoot should generalize to other templates) YouTube tutorial step by step ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:2:1","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"blogs is-there-a-place-we-can-put-non-blog-files-pdf-files-in-blogdown how-to-make-a-mulilingual-website-with-hugo ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:2:2","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"misc Font_Awesome.docset (icons) Common Issues If your page under development mode crashed, be patient and maybe reload the server in terminal with Ctrl-C and hugo server -D Be careful about syntax, format, especially with multilingual setting. If youâ€™re not sure the organization, always refer to the themes/xxx(LoveIt)/exampleSite folder first thatâ€™s contained in every Hugo repo after you clone it. When you want to add the featured image for the content preview in the home page, do: resources: - name: \"featured-image\" src: \"featured-image.png\" and name your md file to be index.md. Donâ€™t forget to add the \u003c!--more--\u003e divider if you want to tell Hugo only summarizes the content before divider in preview. ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:2:3","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"3. Publish your page Publishing the page is a bit of hassle for me. My sincere suggestion after this experience is to find a tutorial and closely follow the steps. Even if you donâ€™t like the theme or the tutorial style, itâ€™s always easier to build up your understanding first and level up/optimize from there. I used GitHub to host my website and here is a list of docs/blogs that I referred to: https://hongtaoh.com/en/2021/04/05/hugo-deploy-github-actions/ https://gohugo.io/hosting-and-deployment/hosting-on-github/ https://levelup.gitconnected.com/build-a-personal-website-with-github-pages-and-hugo-6c68592204c7 https://www.pluralsight.com/guides/how-to-host-your-static-webpages-on-github-pages ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:3:0","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"4. Other details ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:4:0","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"comment To set up utterances comment section, I updated both config.toml and installed utterances app to repo. There are other alternatives like Disqus and Valine. ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:4:1","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["ç¬”è®°"],"content":"gdocs shortcodes Thanks to Ashish Tiwariâ€™s shortcodes post and wowchemy-hugo-modules, Iâ€™m able to incorporate the gdocs shortcodes functionality. In particular, be aware in your shortcodes {{\u003cgdocs src=\"???\"\u003e}} , the src url should be the one published to web (in your google slides, go to File and then Publish to the web, select either link or embed and copy the url in src=\"???\"), not the shared url. I corrected this once I found only my laptop web can show gdocs (also the display is not very satisfactory) while ipad and iphone canâ€™t. Specifial thanks to Cecina Babich Morrowâ€™s post. ","date":"2021-11-10","objectID":"/zh-cn/hugo_tutorial/:4:2","tags":["å®‰è£…","è®¾ç½®","ç½‘ç«™"],"title":"Hugoç½‘ç«™æ­å»ºç»éªŒå¸–","uri":"/zh-cn/hugo_tutorial/"},{"categories":["åšå®¢"],"content":"èŠ±ä¸€äº›æ—¶é—´æ¥æ›´æ–°æˆ‘å¯¹â€œp-valueâ€çš„ç†è§£, å¹¶åœ¨æ­¤å¤„åšä¸ªç¬”è®°","date":"2020-09-01","objectID":"/zh-cn/stats_pvalue/","tags":["på€¼","ç»Ÿè®¡","å‡è®¾æ£€éªŒ"],"title":"å¯¹å‡è®¾æ£€éªŒä¸­på€¼çš„åæ€","uri":"/zh-cn/stats_pvalue/"},{"categories":["åšå®¢"],"content":"I feel this topic is rather important and worthy to dive into as 3 out of my 4 courses this semester have covered this concept. Yet having learned p-value and hypothesis testing on my AP course early since high school and my college introductory stats course, it always remains a bit foggy. Thus, it would be good to review for learning consolidation and future reference. ","date":"2020-09-01","objectID":"/zh-cn/stats_pvalue/:0:0","tags":["på€¼","ç»Ÿè®¡","å‡è®¾æ£€éªŒ"],"title":"å¯¹å‡è®¾æ£€éªŒä¸­på€¼çš„åæ€","uri":"/zh-cn/stats_pvalue/"},{"categories":["åšå®¢"],"content":"1. What does it actually mean to reject the null? Rejecting null doesnâ€™t mean itâ€™s true, it just means we fail to prove itâ€™s false. $H_{0}$ and $H_{1}$ are not the opposites. Itâ€™s not like one way or the other. Assume null is true, there has happend a low probability event. It seems too rare to happen but if it does happen, then itâ€™s reasonable to suspect the validity of the null. ","date":"2020-09-01","objectID":"/zh-cn/stats_pvalue/:1:0","tags":["på€¼","ç»Ÿè®¡","å‡è®¾æ£€éªŒ"],"title":"å¯¹å‡è®¾æ£€éªŒä¸­på€¼çš„åæ€","uri":"/zh-cn/stats_pvalue/"},{"categories":["åšå®¢"],"content":"2. Hypothesis testing According to Wooldrigeâ€™s textbook: thereâ€™re two approaches. classical: compare critical value with test statistic, if test statistic \u003e critical value, then reject, because we get a sufficiently large value compared to the null. note as $\\alpha$ significance level decreases, the critical value increases, which means it becomes harder to reject the null and one needs larger test statistic for rejection. For example, if I can reject the null at 5 % significance level, I can surely reject it at 10%. p-value: calculate p-value and compare it to sigficance level, if p-value \u003c significance level, reject the null, vice versa. ","date":"2020-09-01","objectID":"/zh-cn/stats_pvalue/:2:0","tags":["på€¼","ç»Ÿè®¡","å‡è®¾æ£€éªŒ"],"title":"å¯¹å‡è®¾æ£€éªŒä¸­på€¼çš„åæ€","uri":"/zh-cn/stats_pvalue/"},{"categories":["åšå®¢"],"content":"3. Additional thoughts Given the observed value of the t statistic, p value is the smallest significance level (alpha) at which the null hypothesis would be rejected. â€“ Cited from Wooldrige To put it in my own understanding, if p-value is 0.03, it means we would observe test statistic as extreme 3% of time when null is true. Smaller p means stronger evidence against $H_{0}$. To compare it with $\\alpha$ the signficance level is to make sure if we were to reject the null 3% of time, it should be within the tolerance of error(the significance level), say if $\\alpha$ is 0.05, weâ€™re willing to accept mistakenly reject the null 5% of time when it is actually true. Why say p-value is the smallest significance level? if we calculate p to be 0.03 and we can reject the null at 3% significance level, we can certainly reject this at 5% if set by the question. ","date":"2020-09-01","objectID":"/zh-cn/stats_pvalue/:3:0","tags":["på€¼","ç»Ÿè®¡","å‡è®¾æ£€éªŒ"],"title":"å¯¹å‡è®¾æ£€éªŒä¸­på€¼çš„åæ€","uri":"/zh-cn/stats_pvalue/"},{"categories":["projects"],"content":"æˆ‘åœ¨ UW-Madison Data Science Club ä¸»åŠçš„ Data Challenge ä¸­çš„é¡¹ç›®æ¦‚è¿°","date":"2020-11-05","objectID":"/zh-cn/data_challenge_2020/","tags":["æœºå™¨å­¦ä¹ ","ç»Ÿè®¡","æ•°æ®åˆ†æ","Python"],"title":"å¿ƒåŠ›è¡°ç«­æ­»äº¡é¢„æµ‹é¡¹ç›®-Data Challenge 2020","uri":"/zh-cn/data_challenge_2020/"},{"categories":["projects"],"content":"1.What I did In Junior Fall 2020, I collaborated with Shaonan Wang, an ISYE major at UW-Madison, on the Data Challenge hosted by Data Science Club. The task was to preprocess the dataset given and develop best prediction statiscal/ML models possible (â€œbestâ€ means highest accuracy) The dataset came from Kaggle.com, about predicting death due to heart failure based on twelve health characteristics on almost 300 patients (diabetes, high blood pressure, etc.). We applied Logistic Regression and Random Forest, with the latter achieving 87% at the end. For model evaluation, we used confusion matrix and ROC curve. Finally, we did an analysis report and presented our findings to professors and other teams. ","date":"2020-11-05","objectID":"/zh-cn/data_challenge_2020/:1:0","tags":["æœºå™¨å­¦ä¹ ","ç»Ÿè®¡","æ•°æ®åˆ†æ","Python"],"title":"å¿ƒåŠ›è¡°ç«­æ­»äº¡é¢„æµ‹é¡¹ç›®-Data Challenge 2020","uri":"/zh-cn/data_challenge_2020/"},{"categories":["projects"],"content":"2.Final results deliverables ğŸ‘‰ colab code ğŸ‘‰ analysis report slides ","date":"2020-11-05","objectID":"/zh-cn/data_challenge_2020/:2:0","tags":["æœºå™¨å­¦ä¹ ","ç»Ÿè®¡","æ•°æ®åˆ†æ","Python"],"title":"å¿ƒåŠ›è¡°ç«­æ­»äº¡é¢„æµ‹é¡¹ç›®-Data Challenge 2020","uri":"/zh-cn/data_challenge_2020/"},{"categories":["projects"],"content":"2020å¹´å¤å­£EconExå®ä¹ , é€šè¿‡Pythonç¼–ç¨‹çš„ç‹¬ç«‹é¡¹ç›®","date":"2020-08-09","objectID":"/zh-cn/covid19_analysis/","tags":["Python","æ•°æ®åˆ†æ"],"title":"Covid-19ä¸‹çš„çº½çº¦ï¼šæ¶ˆè´¹è€…å’Œé›¶å”®è¶‹åŠ¿åˆ†æ","uri":"/zh-cn/covid19_analysis/"},{"categories":["projects"],"content":"1. What I did In Summer 2020, I was fortunate to be selected into the EconEx externship program hosted by Econ department. Mentored by UW-Alumni and Data Scientist Micah Lanier, I completed an independent project analyzing New York City consumer and retail trends under Covid-19. Meanwhile, I self-learnt many useful data analysis techniques in Python, like how to use numpy, pandas, matplotlib â€¦ interpolation to fill in missing data and web scraping. ","date":"2020-08-09","objectID":"/zh-cn/covid19_analysis/:1:0","tags":["Python","æ•°æ®åˆ†æ"],"title":"Covid-19ä¸‹çš„çº½çº¦ï¼šæ¶ˆè´¹è€…å’Œé›¶å”®è¶‹åŠ¿åˆ†æ","uri":"/zh-cn/covid19_analysis/"},{"categories":["projects"],"content":"2. Final results For final deliverables, here is the whitepaper and I also made a video presentation: Here is the full code: (I attached it here but theyâ€™re also available on github repo) main.py: import pandas as pd import numpy as np from datetime import datetime import matplotlib.pyplot as plt %matplotlib inline df = pd.read_csv(\"us-counties.csv\",parse_dates=True,index_col=0) pd.options.display.max_rows = 10 df = df['20200304':'20200611'] df.reset_index(inplace=True) df t10 = df.groupby('state').sum().sort_values('cases', ascending=False).head(10) t10 = t10.drop(columns='fips') print (t10.index) t10_list = ['New York', 'New Jersey', 'Illinois', 'California', 'Massachusetts', 'Pennsylvania', 'Michigan', 'Texas', 'Florida', 'Louisiana'] t10 t_c = t10['cases'].to_list() t_d = t10['deaths'].to_list() x = np.arange(len(t10.index)) # the label locations width = 0.35 # the width of the bars fig, ax = plt.subplots(figsize=(12,5)) rects1 = ax.bar(x - width/2, t_c, width, label='cases') rects2 = ax.bar(x + width/2, t_d, width, label='deaths') # Add some text for labels, title and custom x-axis tick labels, etc. ax.set_ylabel('number') ax.set_title('Cases and deaths comparison across top 10 states') ax.set_xticks(x) ax.set_xticklabels(t10.index) #ax.set_yticks(y) #ax.set_yticklabels(y) ax.legend() fig.tight_layout() plt.show() # now I have obtained the top 10 states with cases confirmed. Next I want to plot the contrast between # cases and deaths over time for each state. cov19_counties_bystate_cases = pd.Series(df.groupby(['state','date']).cases.sum()) cov19_counties_bystate_deaths = pd.Series(df.groupby(['state','date']).deaths.sum()) cov19_counties_bystate = pd.DataFrame(cov19_counties_bystate_cases) cov19_counties_bystate['deaths'] = cov19_counties_bystate_deaths cov19_counties_bystate_deaths = pd.Series(cov19_counties.groupby(['state','date']).deaths.sum()) cov19_counties_bystate = pd.DataFrame(cov19_counties_bystate_cases) cov19_counties_bystate['deaths'] = cov19_counties_bystate_deaths cov19_counties_bystate from matplotlib.dates import DateFormatter import matplotlib.dates as mdates cov19_counties.date = pd.to_datetime(cov19_counties.date) pp.figure(figsize=(12,12)) for i, state in enumerate(t10.index): pp.subplot(5,2,i+1) #5 rows, 2 columns pp.plot(cov19_counties_bystate.loc[state].cases,label='cases') pp.plot(cov19_counties_bystate.loc[state].deaths,label='deaths') pp.legend() pp.title(state) #pp.xticks(arange(4), calendar.month_name[3:6+1], rotation=45) pp.tight_layout() # drop rows df = cov19_counties_bystate ax = cov19_counties_bystate.loc['New York'].cases.plot.line(figsize=(12,5)) ax = cov19_counties_bystate.loc['New Jersey'].cases.plot.line(figsize=(12,5)) ax = cov19_counties_bystate.loc['Illinois'].cases.plot.line(figsize=(12,5)) #ax = cov19_counties_bystate.loc['California'].cases.plot.line(figsize=(12,5))''' for state in t10.index[:4+1]: ax = cov19_counties_bystate.loc[state].cases.plot.line(figsize=(12,5)) ax.legend(t10.index[:4+1]) pp.title('states cases') for state in t10.index[:4+1]: ax = cov19_counties_bystate.loc[state].deaths.plot.line(figsize=(12,5)) ax.legend(t10.index[:4+1]) pp.title('states deaths') df[df.state == 'New York'] dfc = df[df.state == 'New York'].pivot_table(index = df[df.state == 'New York'].date, values='cases',aggfunc='sum') dfd = df[df.state == 'New York'].pivot_table(index = df[df.state == 'New York'].date, values='deaths',aggfunc='sum') ax = dfc.plot.line(figsize=(12,5),grid=True,rot=True) dfd.plot.line(figsize=(12,5),grid=True,rot=True,ax=ax) ax.set_xlabel(\"New York\") ax.set_ylabel(\"number\") def plotstate(state_name): dfc = df[df.state == state_name].pivot_table(index = df[df.state == state_name].date, values='cases',aggfunc='sum') dfd = df[df.state == state_name].pivot_table(index = df[df.state == state_name].date, values='deaths',aggfunc='sum') ax = dfc.plot.line(figsize=(12,5),grid=True,rot=True) dfd.plot.line(figsize=(12,5),grid=True,rot=True,ax=ax) ax.set_xlabel(state_name) ax.set_","date":"2020-08-09","objectID":"/zh-cn/covid19_analysis/:2:0","tags":["Python","æ•°æ®åˆ†æ"],"title":"Covid-19ä¸‹çš„çº½çº¦ï¼šæ¶ˆè´¹è€…å’Œé›¶å”®è¶‹åŠ¿åˆ†æ","uri":"/zh-cn/covid19_analysis/"},{"categories":null,"content":" è¯·ç‚¹å‡» è¿™é‡Œ æŸ¥çœ‹æˆ‘çš„æœ€æ–°ç®€å†ã€‚å¦‚æœæ‚¨å¯¹æˆ‘çš„ç½‘ç«™æˆ–å…¶å†…å®¹æœ‰ä»»ä½•æƒ³æ³•æˆ–ä»»ä½•ä¸€èˆ¬æ€§çš„æƒ³æ³•ï¼Œè¯·éšæ—¶ä¸æˆ‘è”ç³»ï¼ May 2020 at Wisconsin State Capitolc.r. Yizhou Lu \" May 2020 at Wisconsin State Capitol ","date":"2021-11-21","objectID":"/zh-cn/about/:0:0","tags":null,"title":"å…³äºæˆ‘","uri":"/zh-cn/about/"},{"categories":null,"content":"æ•™è‚² æˆ‘å«å´”é›¨çœ ï¼Œæ¥è‡ªä¸­å›½ã€‚æˆ‘çš„ä»£è¯æ˜¯å¥¹/å¥¹/å¥¹çš„ã€‚æˆ‘ç›®å‰æ˜¯å¨æ–¯åº·è¾›å¤§å­¦éº¦è¿ªé€Šåˆ†æ ¡çš„ä¸€åå¤§å››å­¦ç”Ÿï¼Œä¸»ä¿®æ•°æ®ç§‘å­¦å’Œç»æµå­¦ï¼ˆæ•°å­¦ï¼‰å¹¶è¾…ä¿®è®¡ç®—æœºç§‘å­¦ã€‚åœ¨ä¸Šå¤§å­¦ä¹‹å‰ï¼Œæˆ‘åœ¨ä¸­å›½å®Œæˆäº†æ‰€æœ‰çš„æ•™è‚²ã€‚ ","date":"2021-11-21","objectID":"/zh-cn/about/:0:1","tags":null,"title":"å…³äºæˆ‘","uri":"/zh-cn/about/"},{"categories":null,"content":"å…´è¶£ Â é˜…è¯» Â è¾…å¯¼ Â ç¼–ç  Â åƒ Â å¬éŸ³ä¹ Â å’Œæˆ‘çš„çŒ«ä¸€èµ·ç© ç ”ç©¶å…´è¶£ Â æœºå™¨å­¦ä¹  Â äººæœºäº¤äº’ï¼ˆHCIï¼‰ Â è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ ","date":"2021-11-21","objectID":"/zh-cn/about/:0:2","tags":null,"title":"å…³äºæˆ‘","uri":"/zh-cn/about/"}]